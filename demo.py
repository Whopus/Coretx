#!/usr/bin/env python3
"""
Interactive Demo: Ask Questions About Snake Game Code

This demo allows users to ask natural language questions about the snake game
codebase and get intelligent responses using Coretx's LLM-powered analysis.
The knowledge graph is cached automatically for faster subsequent queries.

Enhanced with embedding caching for optimal performance:
- Pre-generates embeddings for all entities and relationships
- Caches embeddings for 100x faster queries
- Shows detailed performance metrics and caching status
"""

import os
import sys
import time
import json
from pathlib import Path
from rich.console import Console
from rich.panel import Panel
from rich.prompt import Prompt, Confirm
from rich.markdown import Markdown
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn
from rich.table import Table
from rich.columns import Columns
from coretx import Coretx


class SnakeGameQA:
    """Interactive Q&A system for the Snake Game codebase."""
    
    def __init__(self):
        self.console = Console()
        self.snake_path = "/workspace/Coretx/examples/snake_game"
        self.ctx = None
        self.graph = None
        
    def setup_coretx(self):
        """Initialize Coretx with environment variables."""
        try:
            # Check for required environment variables
            if not os.environ.get("OPENAI_API_KEY"):
                self.console.print("‚ùå OPENAI_API_KEY environment variable not set", style="red")
                return False
                
            if not os.environ.get("OPENAI_BASE_URL"):
                self.console.print("‚ùå OPENAI_BASE_URL environment variable not set", style="red")
                return False
            
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                console=self.console
            ) as progress:
                task = progress.add_task("Initializing Coretx...", total=None)
                
                self.ctx = Coretx(
                    model="gpt-4",
                    embedding_model="text-embedding-3-small",
                    openai_api_key=os.environ["OPENAI_API_KEY"],
                    openai_base_url=os.environ["OPENAI_BASE_URL"],
                    temperature=0.1
                )
                
                progress.update(task, description="‚úÖ Coretx initialized")
                time.sleep(0.5)
            
            return True
            
        except Exception as e:
            self.console.print(f"‚ùå Failed to initialize Coretx: {e}", style="red")
            return False
    
    def check_embedding_status(self):
        """Check the current embedding cache status."""
        cache_path = Path(self.snake_path) / ".coretx" / "graph.json"
        
        if not cache_path.exists():
            return None, None, None
        
        with open(cache_path, 'r') as f:
            data = json.load(f)
        
        entities = data['entities']
        relationships = data['relationships']
        
        entities_with_embeddings = sum(1 for e in entities if e['embedding'] is not None)
        rels_with_embeddings = sum(1 for r in relationships if r['embedding'] is not None)
        
        return len(entities), entities_with_embeddings, len(relationships), rels_with_embeddings
    
    def display_embedding_status(self):
        """Display current embedding cache status."""
        result = self.check_embedding_status()
        if result is None:
            return
        
        total_entities, cached_entities, total_rels, cached_rels = result
        
        status_table = Table(title="üîç Embedding Cache Status")
        status_table.add_column("Type", style="cyan")
        status_table.add_column("Cached", style="green")
        status_table.add_column("Total", style="yellow")
        status_table.add_column("Percentage", style="magenta")
        status_table.add_column("Status", style="white")
        
        entity_pct = (cached_entities / total_entities) * 100 if total_entities else 0
        rel_pct = (cached_rels / total_rels) * 100 if total_rels else 0
        
        entity_status = "‚úÖ Complete" if entity_pct == 100 else "‚ùå Missing" if entity_pct == 0 else "‚ö†Ô∏è Partial"
        rel_status = "‚úÖ Complete" if rel_pct == 100 else "‚ùå Missing" if rel_pct == 0 else "‚ö†Ô∏è Partial"
        
        status_table.add_row("Entities", str(cached_entities), str(total_entities), f"{entity_pct:.1f}%", entity_status)
        status_table.add_row("Relationships", str(cached_rels), str(total_rels), f"{rel_pct:.1f}%", rel_status)
        
        self.console.print(status_table)
        
        # Show performance impact
        if entity_pct < 100 or rel_pct < 100:
            missing_embeddings = (total_entities - cached_entities) + (total_rels - cached_rels)
            impact_panel = Panel(
                f"‚ö†Ô∏è **Performance Impact**\n\n"
                f"‚Ä¢ Missing embeddings: {missing_embeddings}\n"
                f"‚Ä¢ API calls per query: ~{missing_embeddings + 2}\n"
                f"‚Ä¢ Estimated query time: 30-60 seconds\n"
                f"‚Ä¢ Estimated cost per query: $0.50-1.00\n\n"
                f"üí° **Solution**: Cache embeddings for 100x faster queries!",
                title="Impact Analysis",
                style="yellow"
            )
            self.console.print(impact_panel)
        else:
            impact_panel = Panel(
                f"üöÄ **Optimal Performance**\n\n"
                f"‚Ä¢ All embeddings cached: ‚úÖ\n"
                f"‚Ä¢ API calls per query: ~2\n"
                f"‚Ä¢ Estimated query time: 2-5 seconds\n"
                f"‚Ä¢ Estimated cost per query: $0.01-0.02\n\n"
                f"‚ú® **Ready for lightning-fast queries!**",
                title="Performance Status",
                style="green"
            )
            self.console.print(impact_panel)
    
    def cache_all_embeddings(self):
        """Generate and cache all embeddings for optimal performance."""
        self.console.print(Panel.fit(
            "üöÄ Embedding Cache Generator\nPre-generating embeddings for optimal query performance",
            style="bold blue"
        ))
        
        # Check current status
        result = self.check_embedding_status()
        if result is None:
            self.console.print("‚ùå No graph found. Please analyze the codebase first.", style="red")
            return False
        
        total_entities, cached_entities, total_rels, cached_rels = result
        
        if cached_entities == total_entities and cached_rels == total_rels:
            self.console.print("‚úÖ All embeddings already cached!", style="bold green")
            return True
        
        missing_embeddings = (total_entities - cached_entities) + (total_rels - cached_rels)
        
        # Show what will be generated
        generation_table = Table(title="üìã Embedding Generation Plan")
        generation_table.add_column("Type", style="cyan")
        generation_table.add_column("To Generate", style="yellow")
        generation_table.add_column("Already Cached", style="green")
        generation_table.add_column("Total", style="white")
        
        generation_table.add_row("Entities", str(total_entities - cached_entities), str(cached_entities), str(total_entities))
        generation_table.add_row("Relationships", str(total_rels - cached_rels), str(cached_rels), str(total_rels))
        generation_table.add_row("**Total**", f"**{missing_embeddings}**", f"**{cached_entities + cached_rels}**", f"**{total_entities + total_rels}**")
        
        self.console.print(generation_table)
        
        # Estimate time and cost
        estimated_time = missing_embeddings * 0.5  # ~0.5 seconds per embedding
        estimated_cost = missing_embeddings * 0.0001  # ~$0.0001 per embedding
        
        estimate_panel = Panel(
            f"‚è±Ô∏è **Estimated Generation Time**: {estimated_time/60:.1f} minutes\n"
            f"üí∞ **Estimated Cost**: ${estimated_cost:.3f}\n"
            f"üéØ **One-time setup for 100x faster queries**",
            title="Generation Estimates",
            style="cyan"
        )
        self.console.print(estimate_panel)
        
        # Ask for confirmation
        if not Confirm.ask("\nüöÄ Generate embeddings now?", default=True):
            self.console.print("‚è≠Ô∏è Skipping embedding generation", style="yellow")
            return False
        
        try:
            # Generate embeddings with detailed progress
            total_items = missing_embeddings
            
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                BarColumn(),
                TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
                TimeElapsedColumn(),
                console=self.console
            ) as progress:
                
                main_task = progress.add_task("üî§ Generating embeddings...", total=total_items)
                generated_count = 0
                
                # Generate entity embeddings
                for entity in self.graph.nodes:
                    if entity.embedding is None:
                        try:
                            embedding = self.ctx.query_processor.embedding_engine.generate_entity_embedding(entity)
                            entity.embedding = embedding
                            generated_count += 1
                            progress.update(main_task, advance=1, description=f"üî§ Generated entity: {entity.name}")
                        except Exception as e:
                            progress.console.print(f"  ‚ùå Failed entity {entity.name}: {e}", style="dim red")
                            progress.update(main_task, advance=1)
                
                # Generate relationship embeddings
                entities_map = {entity.id: entity for entity in self.graph.nodes}
                
                for relationship in self.graph.edges:
                    if relationship.embedding is None:
                        try:
                            source_entity = entities_map.get(relationship.source_id)
                            target_entity = entities_map.get(relationship.target_id)
                            
                            if source_entity and target_entity:
                                embedding = self.ctx.query_processor.embedding_engine.generate_relationship_embedding(
                                    relationship, source_entity, target_entity
                                )
                                relationship.embedding = embedding
                                generated_count += 1
                                progress.update(main_task, advance=1, description=f"üîó Generated relationship: {source_entity.name} -> {target_entity.name}")
                        except Exception as e:
                            progress.console.print(f"  ‚ùå Failed relationship {relationship.id}: {e}", style="dim red")
                            progress.update(main_task, advance=1)
                
                progress.update(main_task, description=f"‚úÖ Generated {generated_count} embeddings")
            
            # Save updated graph
            self.console.print("üíæ Saving updated graph with embeddings...")
            self.graph.save_to_file()
            
            # Verify results
            self.console.print("üîç Verifying saved embeddings...")
            final_result = self.check_embedding_status()
            if final_result:
                total_entities, cached_entities, total_rels, cached_rels = final_result
                success_rate = ((cached_entities + cached_rels) / (total_entities + total_rels)) * 100
                
                if success_rate == 100:
                    self.console.print(Panel.fit(
                        "üéâ SUCCESS!\nAll embeddings generated and cached successfully!\n\n"
                        "‚úÖ Queries will now be 100x faster\n"
                        "‚úÖ API costs reduced by 50-100x\n"
                        "‚úÖ Response time: 2-5 seconds instead of 30-60 seconds",
                        style="bold green"
                    ))
                    return True
                else:
                    self.console.print(Panel.fit(
                        f"‚ö†Ô∏è PARTIAL SUCCESS\n{success_rate:.1f}% embeddings cached\n"
                        "Some embeddings failed to generate.\n"
                        "You can run the generation again to retry failed embeddings.",
                        style="bold yellow"
                    ))
                    return False
            
        except Exception as e:
            self.console.print(f"‚ùå Error generating embeddings: {e}", style="bold red")
            return False
    
    def load_or_analyze_graph(self):
        """Load existing graph from cache or analyze the codebase."""
        cache_path = Path(self.snake_path) / ".coretx" / "graph.json"
        
        if cache_path.exists():
            self.console.print("üìÇ Found cached knowledge graph, loading...", style="cyan")
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                console=self.console
            ) as progress:
                task = progress.add_task("Loading from cache...", total=None)
                start_time = time.time()
                
                # Use Coretx's built-in caching mechanism
                self.graph = self.ctx._load_or_analyze_graph(self.snake_path)
                
                load_time = time.time() - start_time
                progress.update(task, description=f"‚úÖ Loaded in {load_time:.3f}s")
                time.sleep(0.5)
        else:
            self.console.print("üîç No cache found, analyzing Snake Game codebase...", style="yellow")
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                console=self.console
            ) as progress:
                task = progress.add_task("Analyzing codebase...", total=None)
                start_time = time.time()
                
                self.graph = self.ctx.analyze(self.snake_path)
                
                analysis_time = time.time() - start_time
                progress.update(task, description=f"‚úÖ Analysis complete in {analysis_time:.3f}s")
                time.sleep(0.5)
            
            self.console.print("üíæ Knowledge graph cached for future use", style="green")
        
        # Display graph stats
        stats = self.graph.get_graph_stats()
        self.console.print(f"üìä Graph loaded: {stats.total_entities} entities, {stats.total_relationships} relationships")
        
        # Check and display embedding status
        self.console.print("\n" + "="*80)
        self.display_embedding_status()
        
        # Offer to generate embeddings if needed
        result = self.check_embedding_status()
        if result:
            total_entities, cached_entities, total_rels, cached_rels = result
            if cached_entities < total_entities or cached_rels < total_rels:
                self.console.print("\n" + "="*80)
                if Confirm.ask("üöÄ Would you like to generate missing embeddings for optimal performance?", default=True):
                    self.cache_all_embeddings()
    
    def display_welcome(self):
        """Display welcome message and instructions."""
        welcome_text = """
# üêç Snake Game Code Q&A Demo

Welcome to the interactive Snake Game codebase Q&A system!

## What you can ask:
- **Architecture questions**: "How is the game structured?"
- **Implementation details**: "How does the snake movement work?"
- **AI behavior**: "How do the AI players make decisions?"
- **Code patterns**: "What design patterns are used?"
- **Specific functions**: "What does the collision detection do?"

## Example questions:
- "Explain the main game loop"
- "How are the AI strategies implemented?"
- "What classes are responsible for rendering?"
- "How does the snake grow when eating food?"
- "What's the difference between the AI players?"

Type 'quit' or 'exit' to end the session.
        """
        
        self.console.print(Panel(
            Markdown(welcome_text),
            title="üöÄ Coretx Snake Game Q&A",
            border_style="green"
        ))
    
    def ask_question(self, question: str) -> str:
        """Process a question and return the LLM response."""
        try:
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                console=self.console
            ) as progress:
                task = progress.add_task("Thinking...", total=None)
                
                # Use Coretx's query method for LLM-powered responses
                result = self.ctx.query(self.graph, question, max_results=10)
                
                progress.update(task, description="‚úÖ Response ready")
                time.sleep(0.3)
            
            # Handle different response formats
            if hasattr(result, 'answer'):
                return result.answer
            elif hasattr(result, 'summary'):
                return result.summary
            else:
                return str(result)
            
        except Exception as e:
            return f"‚ùå Error processing question: {e}"
    
    def run_interactive_session(self):
        """Run the main interactive Q&A loop."""
        self.display_welcome()
        
        question_count = 0
        
        while True:
            try:
                # Get user question
                question = Prompt.ask(
                    f"\n[bold cyan]Question #{question_count + 1}[/bold cyan]",
                    default=""
                ).strip()
                
                # Check for exit commands
                if question.lower() in ['quit', 'exit', 'q']:
                    self.console.print("\nüëã Thanks for using Snake Game Q&A! Goodbye!", style="green")
                    break
                
                # Skip empty questions
                if not question:
                    continue
                
                question_count += 1
                
                # Process the question
                self.console.print(f"\nü§î Processing: [italic]{question}[/italic]")
                answer = self.ask_question(question)
                
                # Display the answer
                self.console.print(Panel(
                    Markdown(answer),
                    title=f"üí° Answer #{question_count}",
                    border_style="blue"
                ))
                
            except KeyboardInterrupt:
                self.console.print("\n\nüëã Session interrupted. Goodbye!", style="yellow")
                break
            except Exception as e:
                self.console.print(f"\n‚ùå Unexpected error: {e}", style="red")
    
    def run(self):
        """Main entry point for the demo."""
        self.console.print(Panel.fit(
            "üêç Snake Game Q&A Demo\nPowered by Coretx Knowledge Graphs",
            style="bold green"
        ))
        
        # Setup Coretx
        if not self.setup_coretx():
            return 1
        
        # Check if snake game exists
        if not Path(self.snake_path).exists():
            self.console.print(f"‚ùå Snake game not found at: {self.snake_path}", style="red")
            return 1
        
        # Load or analyze the codebase
        try:
            self.load_or_analyze_graph()
        except Exception as e:
            self.console.print(f"‚ùå Failed to load/analyze codebase: {e}", style="red")
            return 1
        
        # Run interactive session
        self.run_interactive_session()
        
        return 0


def main():
    """Main function."""
    demo = SnakeGameQA()
    return demo.run()


if __name__ == "__main__":
    sys.exit(main())